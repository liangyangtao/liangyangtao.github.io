---
layout: post
title: 网络爬虫（三）【文档判重】
category: 网络爬虫
date: 2015-03-10
---

标签： 网络爬虫 信息采集

<!-- more -->

##  前言
 在采集的文档中，有些网页是一样的，有些网页是转载的，还有一些文本内容大部分是一样的，我们有必要去除这部分重复的文档，如果用户搜索的文章，给出都是同一片内容的文章的列表，用户体验就不是很好了。
##CheckSum值排重
 最简单的方法是比较CheckSum 值，如果CheckSum 值不匹配则就可以看做不同的文档
 可以把文本进行MD5加密，得到文章的Md5值，好处是简单，缺点很明显，对同一内容的文章很有效，如果文章稍微改动一点就判断不出了。
##关键词排重
 具体做法是将文档看成是基于词的特征向量，提取出文章的关键词，提取关键词可以用TF*TDF ，也可以用PageRank 算法。
 得出关键词后，按照权值排序
 选择前10个特征词，按照字符排序，
 调用MD5算法，将特征词串加密，生成文档的指纹。
 比较每篇文章的指纹即可。
##SimHash排重
 这个也是基于关键词排重的，只不过用的是simhash是将一个文档，最后转换成一个64位的字节，暂且称之为特征字，然后判断重复只需要判断他们的特征字的距离
 是不是小于n（根据经验这个n一般取值为3），就可以判断两个文档是否相似。
 判断特征字的距离用海明距离计算
 当我们算出所有doc的simhash值之后，需要计算doc A和doc B之间是否相似的条件是：
 A和B的海明距离是否小于等于n，这个n值根据经验一般取值为3,
 simhash本质上是局部敏感性的hash，和md5之类的不一样。
 正因为它的局部敏感性，所以我们可以使用海明距离来衡量simhash值的相似度。
 下面这个文档介绍的很不错：
 http://www.open-open.com/lib/view/open1375690611500.html
##shingle算法排重
shingling算法用于计算两个文档的相似度，例如，用于网页去重。
维基百科用一个浅显的例子讲解了shingling算法的原理。比如，一个文档
 "a rose is a rose is a rose"
分词后的词汇(token，语汇单元)集合是
(a,rose,is,a,rose,is, a, rose)
那么w=4的4-shingling就是集合:
{ (a,rose,is,a), (rose,is,a,rose), (is,a,rose,is), (a,rose,is,a), (rose,is,a,rose) }
去掉重复的子集合：
   { (a,rose,is,a), (rose,is,a,rose), (is,a,rose,is) }
给定shingle的大小,两个文档A和B的相似度 r 定义为:
   r(A,B)=|S(A)∩S(B)| / |S(A)∪S(B)|
其中|A|表示集合A的大小。
因此,相似度是介于0和1之间的一个数值，且r(A,A)=1,即一个文档和它自身 100%相似。
个人用这个做去重，感觉去重有点狠，会有1/3的文档会被去掉，不过我们是只要有30%一样就算重复了。
##网页去重-算法篇
I-Match
Shingling
SimHashing（ locality sensitive hash）
Random Projection
SpotSig
combined


 
 





